{"createdAt":"2025-02-12T00:53:52.494Z","updatedAt":"2025-02-27T11:42:18.000Z","id":"BLViGWFhMcv1t1dB","name":"Scrive la didascalia delle immagini con Gemini 1.5 Pro","active":false,"nodes":[{"parameters":{},"id":"c8ee9a11-bb00-4d36-a57f-089cf56b3baa","name":"When clicking ‘Test workflow’","type":"n8n-nodes-base.manualTrigger","position":[560,220],"typeVersion":1},{"parameters":{"modelName":"models/gemini-1.5-flash","options":{}},"id":"8c46620e-ed4d-4ff1-8f4a-91ef3c1a769a","name":"Google Gemini Chat Model","type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","position":[1400,640],"typeVersion":1,"credentials":{"googlePalmApi":{"id":"hKHVfBTkYp9RvMAM","name":"Google Gemini(PaLM) Api account"}}},{"parameters":{"jsonSchemaExample":"{\n\t\"caption_title\": \"\",\n\t\"caption_text\": \"\"\n}"},"id":"45e434c4-720a-41cf-b81a-69f00c947eb6","name":"Structured Output Parser","type":"@n8n/n8n-nodes-langchain.outputParserStructured","position":[1600,640],"typeVersion":1.2},{"parameters":{"operation":"information"},"id":"e8598066-49d8-4c36-ba86-4db3b3441249","name":"Get Info","type":"n8n-nodes-base.editImage","position":[1220,320],"typeVersion":1},{"parameters":{"operation":"resize","width":512,"height":512,"options":{}},"id":"4119c8d1-300a-4c0a-9e35-d24e89d30c74","name":"Resize For AI","type":"n8n-nodes-base.editImage","position":[1220,480],"typeVersion":1},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const { size, output } = $input.item.json;\n\nconst lineHeight = 35;\nconst fontSize = Math.round(size.height / lineHeight);\nconst maxLineLength = Math.round(size.width/fontSize) * 2;\nconst text = `\"${output.caption_title}\". ${output.caption_text}`;\nconst numLinesOccupied = Math.round(text.length / maxLineLength);\n\nconst verticalPadding = size.height * 0.02;\nconst horizontalPadding = size.width * 0.02;\nconst rectPosX = 0;\nconst rectPosY = size.height - (verticalPadding * 2.5) - ((numLinesOccupied+1) * fontSize);\nconst textPosX = horizontalPadding;\nconst textPosY = size.height - ((numLinesOccupied+2) * fontSize) - (verticalPadding/2);\n\nreturn {\n  caption: {\n    fontSize,\n    maxLineLength,\n    numLinesOccupied,\n    rectPosX,\n    rectPosY,\n    textPosX,\n    textPosY,\n    verticalPadding,\n    horizontalPadding,\n  }\n}\n"},"id":"e2dc24e3-e783-45b8-8041-74b06f5046b4","name":"Calculate Positioning","type":"n8n-nodes-base.code","position":[2140,640],"typeVersion":2},{"parameters":{"operation":"multiStep","operations":{"operations":[{"operation":"draw","color":"=#0000008c","startPositionX":"={{ $json.caption.rectPosX }}","startPositionY":"={{ $json.caption.rectPosY }}","endPositionX":"={{ $json.size.width }}","endPositionY":"={{ $json.size.height }}"},{"operation":"text","text":"=\"{{ $json.output.caption_title }}\". {{ $json.output.caption_text }}","fontSize":"={{ $json.caption.fontSize }}","fontColor":"#FFFFFF","positionX":"={{ $json.caption.textPosX }}","positionY":"={{ $json.caption.textPosY }}","lineLength":"={{ $json.caption.maxLineLength }}","font":"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf"}]},"options":{}},"id":"a1d9cd4f-54da-475b-8615-cbc21b035293","name":"Apply Caption to Image","type":"n8n-nodes-base.editImage","position":[2500,480],"typeVersion":1},{"parameters":{"content":"## Funziona!\n\n### Bisogna aggiungere un ciclo per lavorare tutte le immagini di una cartella.\n\nBisogna aggiungere al nome dell'immagine con didascalia un suffisso con nomecartella o simile\n\nBisogna spostare didascalie al centro immagine (anticopia?)\n\nBisogna salvare la didascalia con lo stesso nome dell'immagine e differente estensione\n","height":312,"width":584,"color":4},"id":"246992f7-bc8e-4957-8810-1538506d3b14","name":"Sticky Note","type":"n8n-nodes-base.stickyNote","position":[460,520],"typeVersion":1},{"parameters":{"mode":"combine","combineBy":"combineByPosition","options":{}},"id":"e31394cf-b7da-4a55-96e1-1d3d6b058b35","name":"Merge Image & Caption","type":"n8n-nodes-base.merge","position":[1740,320],"typeVersion":3},{"parameters":{"mode":"combine","combineBy":"combineByPosition","options":{}},"id":"933c624f-89c4-490e-8676-13916d5f5b02","name":"Merge Caption & Positions","type":"n8n-nodes-base.merge","position":[2320,480],"typeVersion":3},{"parameters":{"url":"https://boo.it/celentano.jpg","options":{}},"id":"7e7f0811-8efb-4dc8-8ae5-76b7902ba01d","name":"Get Image","type":"n8n-nodes-base.httpRequest","position":[800,220],"typeVersion":4.2},{"parameters":{"content":"## 1. Import an Image \n[Read more about the HTTP request node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\n\nFor this demonstration, we'll grab an image off Pexels.com - a popular free stock photography site - by using the HTTP request node to download.\n\nIn your own workflows, this can be replaces by other triggers such as webhooks.","height":486.25,"width":586.25,"color":7},"id":"df95b951-0240-4837-a5f8-f190db4870e0","name":"Sticky Note1","type":"n8n-nodes-base.stickyNote","position":[460,0],"typeVersion":1},{"parameters":{"content":"## 2. Using Vision Model to Generate Caption\n[Learn more about the Basic LLM Chain](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm)\n\nn8n's basic LLM node supports multimodal input by allowing you to specify either a binary or an image url to send to a compatible LLM. This makes it easy to start utilising this powerful feature for visual classification or OCR tasks which have previously depended on more dedicated OCR models.\n\nHere, we've simply passed our image binary as a \"user message\" option, asking the LLM to help us generate a caption title and text which is appropriate for the given subject. Once generated, we'll pass this text along with the image to combine them both.","height":783.75,"width":888.75,"color":7},"id":"e857b4c4-9b45-4c79-b045-e6884b61e223","name":"Sticky Note2","type":"n8n-nodes-base.stickyNote","position":[1080,60],"typeVersion":1},{"parameters":{"content":"## 3. Overlay Caption on Image \n[Read more about the Edit Image node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.editimage)\n\nFinally, we’ll perform some basic calculations to place the generated caption onto the image. With n8n's user-friendly image editing features, this can be done entirely within the workflow!\n\nThe Code node tool is ideal for these types of calculations and is used here to position the caption at the bottom of the image. To create the overlay, the Edit Image node enables us to insert text onto the image, which we’ll use to add the generated caption.","height":635,"width":753.75,"color":7},"id":"b7193765-6d70-4111-b173-c2a459f1101a","name":"Sticky Note3","type":"n8n-nodes-base.stickyNote","position":[2000,200],"typeVersion":1},{"parameters":{"content":"**FIG 1.** Example input image with AI generated caption\n![Example Output](https://boo.it/celentano_caption.jpg#half-width)","height":851,"width":564},"id":"b10dbc67-f76d-452a-bda3-e1f85b99d4d6","name":"Sticky Note4","type":"n8n-nodes-base.stickyNote","position":[2780,-20],"typeVersion":1},{"parameters":{"promptType":"define","text":"Generate a caption for this image.","hasOutputParser":true,"messages":{"messageValues":[{"message":"=Il tuo ruolo è quello di fornire una didascalia appropriata per le immagini fornite dall'utente, che finiranno in un catalogo su cui potrà essere effettuata una ricerca in base alle didascalie che aggiungerai.\n\nI singoli componenti di una didascalia sono i seguenti: cosa, quando, dove, contesto e vari. Per una didascalia davvero buona, segui questo modello: cosa + quando + dove + contesto + vari.\n\nNon presumere l'identità del soggetto. Non serve. Descrivi piuttosto il suo aspetto, cosa fa, e che espressione ha: per esempio seria, allegra, spaventata, intensa, rabbiosa\n\nDai alla didascalia un titolo conciso ed efficace."},{"type":"HumanMessagePromptTemplate","messageType":"imageBinary"}]}},"id":"2490f7b4-7ca6-40f4-94ce-ac1317ae0f3d","name":"Image Captioning Agent","type":"@n8n/n8n-nodes-langchain.chainLlm","position":[1400,480],"typeVersion":1.4}],"connections":{"Get Info":{"main":[[{"node":"Merge Image & Caption","type":"main","index":0}]]},"Get Image":{"main":[[{"node":"Resize For AI","type":"main","index":0},{"node":"Get Info","type":"main","index":0}]]},"Resize For AI":{"main":[[{"node":"Image Captioning Agent","type":"main","index":0}]]},"Calculate Positioning":{"main":[[{"node":"Merge Caption & Positions","type":"main","index":1}]]},"Merge Image & Caption":{"main":[[{"node":"Calculate Positioning","type":"main","index":0},{"node":"Merge Caption & Positions","type":"main","index":0}]]},"Image Captioning Agent":{"main":[[{"node":"Merge Image & Caption","type":"main","index":1}]]},"Google Gemini Chat Model":{"ai_languageModel":[[{"node":"Image Captioning Agent","type":"ai_languageModel","index":0}]]},"Structured Output Parser":{"ai_outputParser":[[{"node":"Image Captioning Agent","type":"ai_outputParser","index":0}]]},"Merge Caption & Positions":{"main":[[{"node":"Apply Caption to Image","type":"main","index":0}]]},"When clicking ‘Test workflow’":{"main":[[{"node":"Get Image","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{},"versionId":"fa14ffde-7b36-46b9-9f12-ee3fd7df0348","triggerCount":0,"tags":[{"createdAt":"2025-02-24T14:01:24.403Z","updatedAt":"2025-02-24T14:01:24.403Z","id":"EedSBzjO1Iwg92mL","name":"DA COMPLETARE"},{"createdAt":"2025-02-12T01:27:20.078Z","updatedAt":"2025-02-12T01:27:20.078Z","id":"wKG1EEc4KjZp5Caj","name":"IMAGE"}]}